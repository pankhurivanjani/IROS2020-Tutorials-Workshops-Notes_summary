{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SerketTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEZqFQbuZnKE",
        "outputId": "c242a31c-69bf-43df-cd7b-75a31e322130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# download and install the requires\n",
        "!pip install tensorflow==1.5.0 # currently Serket uses tensorflow 1 \n",
        "!git clone https://github.com/naka-lab/Serket.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/79/a37d0b373757b4d283c674a64127bd8864d69f881c639b1ee5953e2d9301/tensorflow-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (44.4MB)\n",
            "\u001b[K     |████████████████████████████████| 44.4MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (3.12.4)\n",
            "Collecting tensorflow-tensorboard<1.6.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/fa/91c06952517b4f1bc075545b062a4112e30cebe558a6b962816cb33efa27/tensorflow_tensorboard-1.5.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.5.0) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (1.0.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.0MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.3.1)\n",
            "Building wheels for collected packages: html5lib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkE25WN6Zzit"
      },
      "source": [
        "# import modules\n",
        "%cd /content/Serket/\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import serket as srk\n",
        "import vae\n",
        "import gmm\n",
        "import mlda\n",
        "import mm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.cluster import adjusted_rand_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJOtERe-bhZL"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMrMExAUZ4rv"
      },
      "source": [
        "%cd /content/Serket/examples/VAE-GMM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhl5yZvacGl7"
      },
      "source": [
        "## Dataset: MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CERHpoKZ_eT"
      },
      "source": [
        "data = np.loadtxt(\"data.txt\")\n",
        "labels = np.loadtxt( \"category.txt\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seLuXuP7caGZ"
      },
      "source": [
        "plt.imshow( data[1].reshape(28,28), cmap=\"gray\" )\n",
        "print(labels[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of9WdtqJdRf0"
      },
      "source": [
        "## Construct and train the integrated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tUVsX1Cculp"
      },
      "source": [
        "# VAE\n",
        "encoder_dim = 128\n",
        "decoder_dim = 128\n",
        "\n",
        "class vae_model(vae.VAE):\n",
        "    def build_encoder(self, x, latent_dim):\n",
        "        h_encoder = tf.keras.layers.Dense(encoder_dim, activation=\"relu\")(x)\n",
        "\n",
        "        mu = tf.keras.layers.Dense(latent_dim)(h_encoder)\n",
        "        logvar = tf.keras.layers.Dense(latent_dim)(h_encoder)\n",
        "        \n",
        "        return mu, logvar\n",
        "    \n",
        "    def build_decoder(self, z):\n",
        "        h_decoder = tf.keras.layers.Dense(decoder_dim, activation=\"relu\")(z)\n",
        "        logits = tf.keras.layers.Dense(784)(h_decoder)\n",
        "\n",
        "        optimizer = tf.train.AdamOptimizer()\n",
        "        \n",
        "        return logits, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTotjTgcdUb4"
      },
      "source": [
        "# Create instances of the modules\n",
        "obs = srk.Observation( data )\n",
        "vae1 = vae_model( 18, itr=200, batch_size=500 )\n",
        "gmm1 = gmm.GMM( 10 )\n",
        "\n",
        "# Connect modules\n",
        "vae1.connect( obs )\n",
        "gmm1.connect( vae1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8-xUb8tdh8X"
      },
      "source": [
        "# Train the integrated model\n",
        "for i in range(5):\n",
        "    print( i )\n",
        "    vae1.update()\n",
        "    gmm1.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtY6xGVHuQip"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH01oP34uVW1"
      },
      "source": [
        "### Latent space of VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDzLzGliqz5Y"
      },
      "source": [
        "# get the latent variables\n",
        "feats = vae1.get_forward_msg()\n",
        "\n",
        "# compress 18 dims to 2 dims by PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(feats)\n",
        "feats_2dim = pca.transform(feats)\n",
        "\n",
        "# visualization\n",
        "for num in range(10):\n",
        "  f = feats_2dim[num==labels]\n",
        "  plt.plot( f[:,0], f[:,1], \"o\", label=str(num) )\n",
        "\n",
        "plt.legend()\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mjoD0wnudwA"
      },
      "source": [
        "### Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdKKSMVDugf5"
      },
      "source": [
        "# get the probabilities of classificaiton results\n",
        "preds = gmm1.get_forward_msg()\n",
        "\n",
        "# convert them to the labels by argmax operation\n",
        "pred_labels = np.argmax( preds, axis=1 )\n",
        "\n",
        "# compute the score\n",
        "print(\"ARI:\", adjusted_rand_score(pred_labels, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHV_Loe_f-gg"
      },
      "source": [
        "# Example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGs_SMHduSp"
      },
      "source": [
        "%cd /content/Serket/examples/VAE-GMM-MLDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqfbAdJ5gLQV"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei8WCeeKxPqU"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-c4yGyNxdSZ"
      },
      "source": [
        "data1 = np.loadtxt(\"data/data1.txt\")\n",
        "data2 = np.loadtxt(\"data/data2.txt\")\n",
        "labels = np.loadtxt( \"data/category.txt\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21zzNdsixfDQ"
      },
      "source": [
        "# image\n",
        "plt.imshow( data1[0].reshape(28,28), cmap=\"gray\" )\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QKDe1euxuCY"
      },
      "source": [
        "# speech signal: HAC features (https://www.isca-speech.org/archive/interspeech_2008/i08_2554.html)\n",
        "plt.bar( range(2400), data2[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1s_ShkGyZ36"
      },
      "source": [
        "## Construct and train the integrated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3dx7YXGxztk"
      },
      "source": [
        "# Create instances of the modules\n",
        "obs1 = srk.Observation( data1 )\n",
        "obs2 = srk.Observation( data2 )\n",
        "\n",
        "vae1 = vae_model( 18, itr=200, batch_size=500 )\n",
        "gmm1 = gmm.GMM( 10 )\n",
        "mlda1 = mlda.MLDA( 10, [200,200] )\n",
        "\n",
        "# Connect modules\n",
        "vae1.connect( obs1 )\n",
        "gmm1.connect( vae1 )\n",
        "mlda1.connect( obs2, gmm1 )\n",
        "\n",
        "# Train the integrated model\n",
        "for i in range(5):\n",
        "    print( i )\n",
        "    vae1.update()\n",
        "    gmm1.update()\n",
        "    mlda1.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQc-ruf0FYYC"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510GUovDS2KJ"
      },
      "source": [
        "### Latent space of VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxHGfS5HD20"
      },
      "source": [
        "# get the latent variables\n",
        "feats = vae1.get_forward_msg()\n",
        "\n",
        "# compress 18 dims to 2 dims by PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(feats)\n",
        "feats_2dim = pca.transform(feats)\n",
        "\n",
        "# visualization\n",
        "for num in range(10):\n",
        "  f = feats_2dim[num==labels]\n",
        "  plt.plot( f[:,0], f[:,1], \"o\", label=str(num) )\n",
        "\n",
        "plt.legend()\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMF27bhGS6hM"
      },
      "source": [
        "### Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OvY6wUytIH"
      },
      "source": [
        "# get the probabilities of classificaiton results\n",
        "preds = mlda1.get_forward_msg()\n",
        "\n",
        "# convert them to the labels by argmax operation\n",
        "pred_labels = np.argmax( preds, axis=1 )\n",
        "\n",
        "# compute the score\n",
        "print(\"ARI:\", adjusted_rand_score(pred_labels, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faQ5AFphTJhv"
      },
      "source": [
        "# Example 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fH2UCAXTKip"
      },
      "source": [
        "%cd /content/Serket/examples/VAE-GMM-MLDA-MM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjzAL-ocTX-m"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTaHVAhvTQ-n"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcoo2F2TTV_E"
      },
      "source": [
        "data1 = np.loadtxt(\"data/data1.txt\")\n",
        "data2 = np.loadtxt(\"data/data2.txt\")\n",
        "labels = np.loadtxt( \"data/category.txt\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apgwJ_b4TbeU"
      },
      "source": [
        "# image\n",
        "for i in range(20):\n",
        "  plt.subplot( 2, 10, i+1 )\n",
        "  plt.imshow( data1[i].reshape(28,28), cmap=\"gray\" )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pAVs5qMTqNI"
      },
      "source": [
        "# speech signal: HAC features (https://www.isca-speech.org/archive/interspeech_2008/i08_2554.html)\n",
        "plt.bar( range(2400), data2[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HzgZX4pyv5x"
      },
      "source": [
        "## Construct and train the integrated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0bpC6GKT117"
      },
      "source": [
        "# Create instances of the modules\n",
        "obs1 = srk.Observation( data1 )\n",
        "obs2 = srk.Observation( data2 )\n",
        "\n",
        "vae1 = vae_model( 18, itr=200, batch_size=500 )\n",
        "gmm1 = gmm.GMM( 10 )\n",
        "mlda1 = mlda.MLDA( 10, [200,200] )\n",
        "mm1 = mm.MarkovModel()\n",
        "\n",
        "# Connect modules\n",
        "vae1.connect( obs1 )\n",
        "gmm1.connect( vae1 )\n",
        "mlda1.connect( obs2, gmm1 )\n",
        "mm1.connect( mlda1 )\n",
        "\n",
        "# Train the integrated model\n",
        "for i in range(5):\n",
        "    print( i )\n",
        "    vae1.update()\n",
        "    gmm1.update()\n",
        "    mlda1.update()\n",
        "    mm1.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDriJ3UZUKc-"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYlXg072ULnV"
      },
      "source": [
        "### Latent space of VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V_w-CrXULND"
      },
      "source": [
        "# get the latent variables\n",
        "feats = vae1.get_forward_msg()\n",
        "\n",
        "# compress 18 dims to 2 dims by PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(feats)\n",
        "feats_2dim = pca.transform(feats)\n",
        "\n",
        "# visualization\n",
        "for num in range(10):\n",
        "  f = feats_2dim[num==labels]\n",
        "  plt.plot( f[:,0], f[:,1], \"o\", label=str(num) )\n",
        "\n",
        "plt.legend()\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLxXB5SxUOP5"
      },
      "source": [
        "### Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KBDwwLKUPkN"
      },
      "source": [
        "# get the probabilities of classificaiton results\n",
        "preds = mlda1.get_forward_msg()\n",
        "\n",
        "# convert them to the labels by argmax operation\n",
        "pred_labels = np.argmax( preds, axis=1 )\n",
        "\n",
        "# compute the score\n",
        "print(\"ARI:\", adjusted_rand_score(pred_labels, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3OikNcUcwN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}